{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from Conversation import Conversation\n",
    "import Text_Preprocessing as TP\n",
    "import math\n",
    "from operator import itemgetter\n",
    "msdialog_filepath = \"data/MSDialog/Intent/MSDialog-Intent.json\"\n",
    "msdialog_classes = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(msdialog_filepath) as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "\n",
    "corpus = []\n",
    "questions = []\n",
    "follow_ups = []\n",
    "for j, thread in enumerate(data.keys()):\n",
    "    messages = data[thread][\"utterances\"]\n",
    "    for i, message in enumerate(messages):\n",
    "        if i == 0 and j > 20 and j < 30:\n",
    "            q_id = message[\"id\"]\n",
    "            questions.append(message)\n",
    "        elif j > 20 and j < 30:\n",
    "            message[\"q_id\"] = q_id\n",
    "            follow_ups.append(message)\n",
    "        corpus.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16436 unique words\n"
     ]
    }
   ],
   "source": [
    "words_occurence = {}\n",
    "for question in corpus:\n",
    "    question_cleaned = TP.preprocess_text(question[\"utterance\"])\n",
    "    for word in set(question_cleaned):\n",
    "        if word not in words_occurence:\n",
    "            words_occurence[word] = 0\n",
    "        words_occurence[word] += 1\n",
    "print(\"{} unique words\".format(len(words_occurence)))\n",
    "del words_occurence['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2738 words with more than 5 occurences\n"
     ]
    }
   ],
   "source": [
    "min_occurences = 5\n",
    "document_count = len(corpus)\n",
    "idf = {key:math.log2(document_count / val) for key, val in words_occurence.items() if val > min_occurences}\n",
    "print(\"{} words with more than {} occurences\".format(len(idf), min_occurences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in questions:\n",
    "    tf = {}\n",
    "    cleaned_message = TP.preprocess_text(question[\"utterance\"])\n",
    "    for word in cleaned_message:\n",
    "        if word not in tf and word in idf:\n",
    "            tf[word] = 0\n",
    "        if word in idf:\n",
    "            tf[word] += 1\n",
    "    tf_idf = {}\n",
    "    for word in tf.keys():\n",
    "        tf_idf[word] = tf[word] * idf[word]\n",
    "\n",
    "    tf_idf = dict(sorted(tf_idf.items(), key = itemgetter(1), reverse = True)[:5])\n",
    "    question[\"tfidf\"] = tf_idf\n",
    "    \n",
    "for follow_up in follow_ups:\n",
    "    tf = {}\n",
    "    cleaned_message = TP.preprocess_text(follow_up[\"utterance\"])\n",
    "    for word in cleaned_message:\n",
    "        if word not in tf and word in idf:\n",
    "            tf[word] = 0\n",
    "        if word in idf:\n",
    "            tf[word] += 1\n",
    "    tf_idf = {}\n",
    "    for word in tf.keys():\n",
    "        tf_idf[word] = tf[word] * idf[word]\n",
    "\n",
    "    tf_idf = dict(sorted(tf_idf.items(), key = itemgetter(1), reverse = True)[:5])\n",
    "    follow_up[\"tfidf\"] = tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for follow_up in follow_ups:\n",
    "    tf_idf_message = follow_up[\"tfidf\"]\n",
    "    best_match = (\"\", 0)\n",
    "    for question in questions:\n",
    "        tf_idf_question = question[\"tfidf\"]\n",
    "        intersect = set(tf_idf_question.keys()).intersection(set(tf_idf_message.keys()))\n",
    "        if len(intersect) > 0:\n",
    "            score = sum([tf_idf_question[item] for item in list(intersect)])\n",
    "            if score > best_match[1]:\n",
    "                best_match = (question[\"id\"], score)\n",
    "    follow_up[\"match\"] = best_match[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3363 3361 3014\n",
      "4512 4511 3014\n",
      "4513 4511 3361\n",
      "7 Correctly Matched. 3 Wrongly Matched. 14 Not Matched\n"
     ]
    }
   ],
   "source": [
    "not_matched = 0\n",
    "matched_correctly = 0\n",
    "match_error = 0\n",
    "for follow_up in follow_ups:\n",
    "    if follow_up[\"match\"] == \"\":\n",
    "        not_matched += 1\n",
    "    elif follow_up[\"q_id\"] != follow_up[\"match\"]:\n",
    "        print(follow_up[\"id\"], follow_up[\"q_id\"], follow_up[\"match\"])\n",
    "        match_error += 1\n",
    "    else:\n",
    "        matched_correctly += 1\n",
    "print(\"{} Correctly Matched. {} Wrongly Matched. {} Not Matched\".format(matched_correctly, match_error, not_matched))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS Dialog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(msdialog_filepath) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "with open('file.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    your_list = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 1\n",
      "16 2\n",
      "16 3\n",
      "25 1\n",
      "25 2\n",
      "25 3\n",
      "25 4\n",
      "25 5\n",
      "36 1\n",
      "36 2\n",
      "36 3\n",
      "36 4\n",
      "36 5\n",
      "40 1\n",
      "40 2\n",
      "40 3\n",
      "40 4\n",
      "40 5\n",
      "40 6\n",
      "74 1\n",
      "74 2\n",
      "74 3\n",
      "74 4\n",
      "74 5\n",
      "74 6\n",
      "75 1\n",
      "75 2\n",
      "75 3\n",
      "77 1\n",
      "77 2\n",
      "77 3\n",
      "77 4\n",
      "96 1\n",
      "96 2\n",
      "96 3\n",
      "96 4\n",
      "96 5\n",
      "96 6\n",
      "96 7\n",
      "103 1\n",
      "103 2\n",
      "103 3\n",
      "103 4\n",
      "103 5\n",
      "103 6\n",
      "103 7\n",
      "103 8\n",
      "103 9\n",
      "103 10\n",
      "106 1\n",
      "106 2\n",
      "106 3\n",
      "147 1\n",
      "147 2\n",
      "147 3\n",
      "147 4\n",
      "147 5\n"
     ]
    }
   ],
   "source": [
    "for j, thread in enumerate(data.keys()):\n",
    "    messages = data[thread][\"utterances\"]\n",
    "    for i, message in enumerate(messages):\n",
    "        print(thread, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
